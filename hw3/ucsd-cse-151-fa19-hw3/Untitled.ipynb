{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "baselines.py: contains all your network structure definition\n",
    "including layers definition and forward pass function definition\n",
    "\"\"\"\n",
    "# PyTorch and neural network imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import math\n",
    "torch.cuda.init()\n",
    "\n",
    "# set the randomness to keep reproducible results\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def conv_out_dim_calculate(in_size, out_channels, kernel_size, stride, padding):\n",
    "    out_width = math.floor((in_size + (2 * padding) - kernel_size)/stride) + 1\n",
    "    return (out_width**2) * out_channels\n",
    "\n",
    "conv_kernel_size = 5\n",
    "conv_out_channels = 10\n",
    "conv_stride = 1\n",
    "conv_padding = 2\n",
    "\n",
    "dummy = 1\n",
    "# input size to your mlp network\n",
    "mlp_input_size = 784 # TODO1\n",
    "# final output size of your mlp network (output layer)\n",
    "mlp_output_size = 10 # TODO2\n",
    "# TODO3: you may need to experiment a bit (width of your hidden layer)\n",
    "mlp_hidden_size = 100\n",
    "\n",
    "class BaselineMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        A multilayer perceptron model\n",
    "        Consists of one hidden layer and 1 output layer (all fully connected)\n",
    "        \"\"\"\n",
    "        super(BaselineMLP, self).__init__()\n",
    "        # a fully connected layer from input layer to hidden layer\n",
    "        # mlp_input_size denotes how many input neurons you have\n",
    "        # mlp_hiddent_size denotes how many hidden neurons you have\n",
    "        self.fc1 = nn.Linear(mlp_input_size, mlp_hidden_size).cuda()\n",
    "        # a fully connected layer from hidden layer to output layer\n",
    "        # mlp_output_size denotes how many output neurons you have\n",
    "        self.fc2 = nn.Linear(mlp_hidden_size, mlp_output_size).cuda()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Pass the batch of images through each layer of the network, applying \n",
    "        logistic activation function after hidden layer.\n",
    "        \"\"\"\n",
    "        # pass X from input layer to hidden layer\n",
    "        out = self.fc1(X.cuda()).cuda()\n",
    "        # apply an activation function to the output of hidden layer\n",
    "        out = torch.sigmoid(out).cuda()\n",
    "        # pass output from hidden layer to output layer\n",
    "        out = self.fc2(out).cuda()\n",
    "        # return the feed forward output\n",
    "        # you don't need to apply another activation function here if\n",
    "        # the loss function you use already implement it for you\n",
    "        return out\n",
    "\n",
    "\n",
    "class BaselineCNN(nn.Module):\n",
    "    def __init__(self, in_dim, in_channels, n_classes):\n",
    "        \"\"\"\n",
    "        A basic convolutional neural network model for baseline comparison.\n",
    "        Consists of one Conv2d layer, followed by 1 fully-connected (FC) layer:\n",
    "        conv1 -> fc1 (outputs)\n",
    "        \"\"\"\n",
    "        super(BaselineCNN, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_out_dim = conv_out_dim_calculate(self.in_dim, conv_out_channels, conv_kernel_size,\n",
    "                                                   conv_stride, conv_padding)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.conv = nn.Conv2d(self.in_channels, conv_out_channels, kernel_size=conv_kernel_size,\n",
    "                              stride=conv_stride, padding=conv_padding).cuda()\n",
    "        self.fc1 = nn.Linear(self.conv_out_dim, n_classes).cuda()\n",
    "        self.softmax = nn.Softmax().cuda()\n",
    "        self.tanh = nn.Tanh().cuda()\n",
    "        # TODO7: define different layers\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Pass the batch of images through each layer of the network, applying \n",
    "        non-linearities after each layer.\n",
    "        \n",
    "        Note that this function *needs* to be called \"forward\" for PyTorch to \n",
    "        automagically perform the forward pass.\n",
    "\n",
    "        You may need the function \"num_fc_features\" below to help implement \n",
    "        this function\n",
    "        \n",
    "        Parameters: X --- an input batch of images\n",
    "        Returns:    out --- the output of the network\n",
    "        \"\"\"\n",
    "        # TODO8: define the forward function\n",
    "        out = self.tanh(self.conv(X.cuda()).view(-1, self.conv_out_dim)).cuda()\n",
    "        out = self.fc1(out).cuda()\n",
    "        return out\n",
    "\n",
    "    \"\"\"\n",
    "    Count the number of flattened features to be passed to fully connected layers\n",
    "    Parameters: inputs --- 4-dimensional [batch x num_channels x conv width x conv height]\n",
    "                            output from the last conv layer\n",
    "    Return: num_features --- total number of flattened features for the last layer\n",
    "    \"\"\"\n",
    "    def num_fc_features(self, inputs):\n",
    "        \n",
    "        # Get the dimensions of the layers excluding the batch number\n",
    "        size = inputs.size()[1:]\n",
    "        # Track the number of features\n",
    "        num_features = 1\n",
    "        \n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        \n",
    "        return num_features\n",
    "\n",
    "\"\"\"\n",
    "TODO: you may need to define your new neural network here\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class TheNameOfYourClass(nn.Module):\n",
    "    def __init__(self, in_dim, in_channels, n_classes):\n",
    "        \"\"\"\n",
    "        A basic convolutional neural network model for baseline comparison.\n",
    "        Consists of one Conv2d layer, followed by 1 fully-connected (FC) layer:\n",
    "        conv1 -> fc1 (outputs)\n",
    "        \"\"\"\n",
    "        super(TheNameOfYourClass, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_out_dim1 = conv_out_dim_calculate(in_size=self.in_dim, out_channels=10,\n",
    "                                                    kernel_size=1, stride=1, padding=0)\n",
    "        self.conv_out_dim2 = conv_out_dim_calculate(in_size=self.conv_out_dim1, out_channels=25,\n",
    "                                                    kernel_size=5, stride=1, padding=2)\n",
    "        # self.conv_out_dim = conv_out_dim_calculate(self.in_dim, conv_out_channels, conv_kernel_size, conv_stride,\n",
    "        #                                            conv_padding)\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=self.in_channels, out_channels=10, kernel_size=1,\n",
    "                               stride=1, padding=0).cuda()\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=25, kernel_size=5,\n",
    "                               stride=1, padding=2).cuda()\n",
    "        # self.conv = nn.Conv2d(self.in_channels, conv_out_channels, kernel_size=conv_kernel_size, stride=conv_stride,\n",
    "        #                       padding=conv_padding).cuda()\n",
    "        self.pl1 = nn.MaxPool2d(2,2).cuda()\n",
    "        self.dropout = nn.Dropout2d(.5).cuda()\n",
    "        self.fc1 = nn.Linear(4900, 2500).cuda()\n",
    "        self.fc2 = nn.Linear(2500, self.n_classes).cuda()\n",
    "        self.softmax = nn.Softmax().cuda()\n",
    "        self.relu = nn.ReLU().cuda()\n",
    "        self.tanh = nn.Tanh().cuda()\n",
    "        # TODO7: define different layers\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Pass the batch of images through each layer of the network, applying\n",
    "        non-linearities after each layer.\n",
    "\n",
    "        Note that this function *needs* to be called \"forward\" for PyTorch to\n",
    "        automagically perform the forward pass.\n",
    "\n",
    "        You may need the function \"num_fc_features\" below to help implement\n",
    "        this function\n",
    "\n",
    "        Parameters: X --- an input batch of images\n",
    "        Returns:    out --- the output of the network\n",
    "        \"\"\"\n",
    "        # TODO8: define the forward function\n",
    "        out = self.relu(self.conv1(X.cuda()))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.pl1(out)\n",
    "        B,C,H,W = out.shape\n",
    "        out = out.view(B, C*H*W)\n",
    "        out = self.relu(self.fc1(out).cuda())\n",
    "        out = self.dropout(out).cuda()\n",
    "        out = self.fc2(out).cuda()\n",
    "        return out\n",
    "\n",
    "    \"\"\"\n",
    "    Count the number of flattened features to be passed to fully connected layers\n",
    "    Parameters: inputs --- 4-dimensional [batch x num_channels x conv width x conv height]\n",
    "                            output from the last conv layer\n",
    "    Return: num_features --- total number of flattened features for the last layer\n",
    "    \"\"\"\n",
    "\n",
    "    def num_fc_features(self, inputs):\n",
    "        # Get the dimensions of the layers excluding the batch number\n",
    "        size = inputs.size()[1:]\n",
    "        # Track the number of features\n",
    "        num_features = 1\n",
    "\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "\n",
    "        return num_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from nn_models import *\n",
    "\n",
    "\"\"\"\n",
    "TODO: You may want to change these parameters\n",
    "\"\"\"\n",
    "num_iter = 50\n",
    "learning_rate = 0.001\n",
    "batch_size = 25\n",
    "\n",
    "\n",
    "# returns: predictions -- rank 1 tensor of predicted labels\n",
    "def evaluate_kaggle(loader, net):\n",
    "    predictions = []\n",
    "    # use model to get predictions\n",
    "    for X in loader:\n",
    "        outputs = net(X[0])\n",
    "        predictions.append(torch.argmax(outputs.data, 1))\n",
    "\n",
    "    return torch.stack(predictions)\n",
    "\n",
    "\n",
    "# returns: data loader for training and validation (images and labels)\n",
    "# and a data loader for testing (no labels)\n",
    "def load_kaggle_data(train_data, val_data, test_data):\n",
    "    # train, validation, and test data loader\n",
    "    data_loaders = []\n",
    "\n",
    "    # read training, test, and validation data\n",
    "    for (data, labels) in [train_data, val_data]:\n",
    "        imgs = data.float()\n",
    "        labels = labels.long()\n",
    "\n",
    "        # divide each image by its maximum pixel value for numerical stability\n",
    "        imgs = imgs / torch.max(imgs, dim=1).values[:, None]\n",
    "\n",
    "        # [batch x num_channel x image width x image height]\n",
    "        imgs = imgs.view(-1, 1, 28, 28)\n",
    "\n",
    "        # create dataset and dataloader, a container to efficiently load data in batches\n",
    "        dataset = utils.TensorDataset(imgs, labels)\n",
    "        dataloader = utils.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        data_loaders.append(dataloader)\n",
    "\n",
    "    test_data = test_data.float()\n",
    "    test_data = test_data / torch.max(test_data, dim=1).values[:, None]\n",
    "    test_dataset = utils.TensorDataset(test_data.view(-1, 1, 28, 28))\n",
    "    test_loader = utils.DataLoader(test_dataset)\n",
    "\n",
    "    return data_loaders[0], data_loaders[1], test_loader\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Read data from the specified training, validation and test data files.\n",
    "We are using the whole image, not creating other features now\n",
    "\"\"\"\n",
    "def read_data(trainFile, valFile, testFile):\n",
    "    # trian, validation, and test data loader\n",
    "    data_loaders = []\n",
    "\n",
    "    # read training, test, and validation data\n",
    "    for file in [trainFile, valFile, testFile]:\n",
    "        # read data\n",
    "        data = np.loadtxt(file)\n",
    "        # digit images\n",
    "        imgs = torch.tensor(data[:,:-1]).float()\n",
    "        # divide each image by its maximum pixel value for numerical stability\n",
    "        imgs = imgs / torch.max(imgs,dim=1).values[:,None]\n",
    "\n",
    "        # labels for each image\n",
    "        labels = torch.tensor(data[:,-1]).long()\n",
    "\n",
    "        # if using CNN model, reshape each image:\n",
    "        # [batch x num_channel x image width x image height]\n",
    "        if not modelNum == 0:\n",
    "            imgs = imgs.view(-1,1,28,28)\n",
    "\n",
    "        # create dataset and dataloader, a container to efficiently load data in batches\n",
    "        dataset = utils.TensorDataset(imgs,labels)\n",
    "        dataloader = utils.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        data_loaders.append(dataloader)\n",
    "    \n",
    "    return data_loaders[0], data_loaders[1], data_loaders[2]\n",
    "\n",
    "\"\"\"\n",
    "Train your Multilayer Perceptron (MLP)\n",
    "Initialize your MLP model --> define loss function --> define optimizer\n",
    "--> train your model with num_iter epochs --> pick the best model and return\n",
    "    - Parameters:   train_loader --- the train dataloader\n",
    "                    val_loader --- the validation dataloader\n",
    "    - Return:       net --- the best trained MLP network with the lowest validation loss\n",
    "                    avg_train_loss --- a list of averaged training loss of length num_iter\n",
    "                    avg_val_loss --- a list of averaged validation loss of length num_iter\n",
    "\"\"\"\n",
    "def trainMLP(train_loader,val_loader, modelNum):\n",
    "    # average training loss, one value per iteration (averaged over all batches in one iteration)\n",
    "    avg_train_loss = []\n",
    "    # average validation loss, one value per iteration (averaged over all batches in one iteration)\n",
    "    avg_val_loss = []\n",
    "    # record the lowest validation loss, used to determine early stopping (best model)\n",
    "    best_val_score = float('inf')\n",
    "    if modelNum == 0:\n",
    "        net = BaselineMLP()\n",
    "    elif modelNum == 1:\n",
    "        net = BaselineCNN(in_dim=28, in_channels=1, n_classes=10)\n",
    "    elif modelNum == 2:\n",
    "        net = TheNameOfYourClass(in_dim=28, in_channels=1, n_classes=10)\n",
    "    # TODO4: define loss function\n",
    "    #       define optimizer\n",
    "    #       for each iteration, iteratively train all batches\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    i = 0\n",
    "    while i < num_iter:\n",
    "        train_loss = 0\n",
    "        net.train()\n",
    "        for x,y in train_loader:\n",
    "            yp = net(x)\n",
    "            loss = loss_func(yp,y.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        # TODO5: implement your training and early stopping\n",
    "        # TODO6: save the best model with lowest validation loss and load it to do testing\n",
    "        torch.save(net.state_dict(), f\"epoch{i}.pt\")\n",
    "\n",
    "        avg_train_loss.append(train_loss)\n",
    "        te_loss = 0\n",
    "        net.eval()\n",
    "        for x,y in val_loader:\n",
    "            yp = net(x)\n",
    "            loss = loss_func(yp,y.cuda())\n",
    "            te_loss += loss.item()\n",
    "        te_loss /= len(val_loader)\n",
    "        avg_val_loss.append(te_loss)\n",
    "        print(f\"Epoch : {i}, Train loss: {train_loss}, Valid/Test loss: {te_loss}\")\n",
    "        i += 1\n",
    "\n",
    "    state_dict = torch.load(f\"epoch{avg_val_loss.index(min(avg_val_loss))}.pt\")\n",
    "    net.load_state_dict(state_dict)\n",
    "        \n",
    "    return net, avg_train_loss, avg_val_loss\n",
    "\n",
    "\"\"\"\n",
    "Train your Baseline Convolutional Neural Network (CNN)\n",
    "Initialize your CNN model --> define loss function --> define optimizer\n",
    "--> train your model with num_iter epochs --> pick the best model and return\n",
    "    - parameters:   train_loader --- the train dataloader\n",
    "                    val_loader --- the validation dataloader\n",
    "    - return:       net --- the best trained CNN network with the lowest validation loss\n",
    "                    train_loss --- a list of training loss\n",
    "\"\"\"\n",
    "def trainCNN(train_loader,val_loader):\n",
    "    # average training loss, one value per iteration (averaged over all batches in one iteration)\n",
    "    avg_train_loss = []\n",
    "    # average validation loss, one value per iteration (averaged over all batches in one iteration)\n",
    "    avg_val_loss = []\n",
    "    # record the lowest validation loss, used to determine early stopping (best model)\n",
    "    best_val_score = float('inf')\n",
    "    net = BaselineCNN()\n",
    "    # TODO9: define loss function\n",
    "    #       define optimizer\n",
    "    #       for each epoch, iteratively train all batches\n",
    "    i = 0\n",
    "    while i < num_iter:\n",
    "        # TODO10: implement your training and early stopping\n",
    "        # TODO11: save the best model with lowest validation loss and load it to do testing\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    return net, avg_train_loss, avg_val_loss\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Evaluate the model, using unseen data features \"X\" and\n",
    "corresponding labels \"y\".\n",
    "Parameters: loader --- the test loader\n",
    "            net --- the best trained network\n",
    "Return: the accuracy on test set\n",
    "\"\"\"\n",
    "def evaluate(loader, net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    # use model to get predictions\n",
    "    for X, y in loader:\n",
    "        outputs = net(X)\n",
    "        predictions = torch.argmax(outputs.data, 1)\n",
    "        \n",
    "        # total number of items in dataset\n",
    "        total += y.shape[0]\n",
    "\n",
    "        # number of correctly labeled items in dataset\n",
    "        correct += torch.sum(predictions == y.cuda())\n",
    "\n",
    "    # return fraction of correctly labeled items in dataset\n",
    "    return float(correct) / float(total)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # TODO: you'll need to change this to False if you want to \n",
    "    # test your CNN model\n",
    "    modelNum = 2\n",
    "\n",
    "    # load data from file\n",
    "    train_loader, val_loader, test_loader = \\\n",
    "        read_data('hw0train.txt','hw0validate.txt', 'hw0test.txt')\n",
    "\n",
    "    net, t_losses, v_losses = trainMLP(train_loader,val_loader, modelNum)\n",
    "\n",
    "    # evaluate model on validation data\n",
    "    accuracy = evaluate(test_loader, net)\n",
    "\n",
    "    print(\"Test accuracy: {}\".format(accuracy))\n",
    "\n",
    "    # plot losses\n",
    "    plt.plot(t_losses)\n",
    "    plt.plot(v_losses)\n",
    "    plt.legend([\"training_loss\",\"validation_loss\"])\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss plot\")\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "    # load data into pytorch tensors\n",
    "    data_x = torch.from_numpy(np.load('kaggle/train/x_train.npy'))\n",
    "    data_y = torch.from_numpy(np.load('kaggle/train/y_train.npy'))\n",
    "    test_data = torch.from_numpy(np.load('kaggle/test/x_test.npy'))\n",
    "\n",
    "    # split into training & validation\n",
    "    val_size = 10000\n",
    "    val_data = (data_x[0:val_size], data_y[0:val_size])\n",
    "    train_data = (data_x[val_size:], data_y[val_size:])\n",
    "\n",
    "    # create DataLoaders\n",
    "    train_loader, val_loader, test_loader = load_kaggle_data(train_data, val_data, test_data)\n",
    "    net, t_losses, v_losses = trainMLP(train_loader, val_loader, modelNum)\n",
    "\n",
    "    # evaluate model on test data\n",
    "    predictions = evaluate_kaggle(test_loader, net)\n",
    "\n",
    "    predictions = predictions.cpu()\n",
    "    pred_numpy = predictions.numpy()[:, 0]  # convert to numpy array\n",
    "\n",
    "    predictions_file = open(\"predictions.txt\", 'w')\n",
    "    predictions_file.write(\"ImageId,Class\\n\")\n",
    "    curr_id = 0\n",
    "    for prediction in pred_numpy:\n",
    "        predictions_file.write(str(curr_id) + \",\" + str(prediction) + \"\\n\")\n",
    "        curr_id += 1\n",
    "    predictions_file.close()\n",
    "    import csv\n",
    "\n",
    "    with open(\"predictions.txt\", 'r') as infile, open(\"result.csv\", 'w', newline='') as outfile:\n",
    "        stripped = (line.strip() for line in infile)\n",
    "        lines = (line.split(\",\") for line in stripped if line)\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerows(lines)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
